import pandas as pd
import numpy as np
from itertools import permutations

# ==========================
# CONFIGURATION – TO EDIT
# ==========================

# Input file paths
INPUT_Q3_PATH = r"sciezka/do/pliku_Q3.csv"
INPUT_Q4_PATH = r"sciezka/do/pliku_Q4.csv"

# Input file type: "csv" or "excel"
INPUT_FILE_TYPE = "csv"   # or "excel"

# Column names in input files
COL_CUSIP        = "cusip"
COL_EAD          = "ead"
COL_RWA          = "rwa"
COL_KG           = "kg"
COL_ATTACH       = "attachment"
COL_DETACH       = "detachment"
COL_W            = "w"
COL_P            = "p"
COL_ASSET_CLASS  = "asset_class"   # asset class

# List of SSFA factors
FACTOR_LIST = [COL_KG, COL_ATTACH, COL_DETACH, COL_W, COL_P]


# ======================================
# FUNCTION: RISK WEIGHT FROM SSFA FACTORS
# ======================================

def compute_rw_from_factors(kg, attachment, detachment, w, p):
    """
    TODO: REPLACE WITH REAL SSFA RW FORMULA.
    This is just a placeholder so the script runs.

    Make sure RW units are consistent with RWA = RW * EAD,
    e.g. RW = 0.15 for 15%, or 1.25 for 125%.
    """
    # --- DUMMY IMPLEMENTATION: REPLACE WITH YOUR OWN ---
    rw = min(kg * 12.5, 12.5)
    return rw


# ==========================
# HELPER FUNCTIONS
# ==========================

def read_input(path: str) -> pd.DataFrame:
    if INPUT_FILE_TYPE.lower() == "csv":
        return pd.read_csv(path)
    elif INPUT_FILE_TYPE.lower() == "excel":
        return pd.read_excel(path)
    else:
        raise ValueError("INPUT_FILE_TYPE must be 'csv' or 'excel'.")


def aggregate_by_cusip(df: pd.DataFrame, period_label: str) -> pd.DataFrame:
    """
    Aggregate by CUSIP:
    - sum EAD and RWA,
    - take asset_class = 'first' (constant per CUSIP),
    - compute EAD-weighted averages of factors (kg, attachment, detachment, w, p).
    """
    cols_needed = [
        COL_CUSIP, COL_EAD, COL_RWA,
        COL_KG, COL_ATTACH, COL_DETACH, COL_W, COL_P,
        COL_ASSET_CLASS,
    ]
    missing = [c for c in cols_needed if c not in df.columns]
    if missing:
        raise KeyError(f"Missing columns in input file: {missing}")

    df = df.copy()

    # Numerators: EAD * factor
    for col in FACTOR_LIST:
        df[f"{col}_num"] = df[col] * df[COL_EAD]

    agg_dict = {
        COL_EAD: "sum",
        COL_RWA: "sum",
        COL_ASSET_CLASS: "first",
    }
    for col in FACTOR_LIST:
        agg_dict[f"{col}_num"] = "sum"

    grouped = df.groupby(COL_CUSIP, as_index=False).agg(agg_dict)

    grouped.rename(
        columns={
            COL_EAD: f"{COL_EAD}_{period_label}",
            COL_RWA: f"{COL_RWA}_{period_label}",
            COL_ASSET_CLASS: f"{COL_ASSET_CLASS}_{period_label}",
        },
        inplace=True,
    )

    ead_col = f"{COL_EAD}_{period_label}"

    # EAD-weighted averages of factors
    for col in FACTOR_LIST:
        num_col = f"{col}_num"
        grouped[f"{col}_{period_label}"] = grouped[num_col] / grouped[ead_col]
        grouped[f"{col}_{period_label}"] = grouped[f"{col}_{period_label}"].replace(
            [np.inf, -np.inf], np.nan
        )

    num_cols = [f"{col}_num" for col in FACTOR_LIST]
    grouped.drop(columns=num_cols, inplace=True)

    return grouped


# ======================================
# Shapley FACTOR EFFECT PER CUSIP
# ======================================

def factor_shapley_effects_row(row: pd.Series) -> pd.Series:
    """
    Shapley values for factor effects on ΔRWA for a single CUSIP.

    Start: all factors at Q3.
    End:   all factors at Q4.
    EAD = EAD_Q4 (effect on final exposure).
    """
    ead4 = row[f"{COL_EAD}_Q4"]

    if pd.isna(ead4) or ead4 == 0:
        return pd.Series({f"{f}_shapley_effect": 0.0 for f in FACTOR_LIST})

    factors_q3 = {
        COL_KG:      row.get(f"{COL_KG}_Q3"),
        COL_ATTACH:  row.get(f"{COL_ATTACH}_Q3"),
        COL_DETACH:  row.get(f"{COL_DETACH}_Q3"),
        COL_W:       row.get(f"{COL_W}_Q3"),
        COL_P:       row.get(f"{COL_P}_Q3"),
    }
    factors_q4 = {
        COL_KG:      row.get(f"{COL_KG}_Q4"),
        COL_ATTACH:  row.get(f"{COL_ATTACH}_Q4"),
        COL_DETACH:  row.get(f"{COL_DETACH}_Q4"),
        COL_W:       row.get(f"{COL_W}_Q4"),
        COL_P:       row.get(f"{COL_P}_Q4"),
    }

    for f in FACTOR_LIST:
        if pd.isna(factors_q3[f]):
            factors_q3[f] = 0.0
        if pd.isna(factors_q4[f]):
            factors_q4[f] = 0.0

    shapley_sums = {f: 0.0 for f in FACTOR_LIST}
    perms = list(permutations(FACTOR_LIST))
    n_perm = len(perms)

    for perm in perms:
        curr_factors = factors_q3.copy()

        rw_prev = compute_rw_from_factors(
            kg=curr_factors[COL_KG],
            attachment=curr_factors[COL_ATTACH],
            detachment=curr_factors[COL_DETACH],
            w=curr_factors[COL_W],
            p=curr_factors[COL_P],
        )

        for f in perm:
            curr_factors[f] = factors_q4[f]

            rw_new = compute_rw_from_factors(
                kg=curr_factors[COL_KG],
                attachment=curr_factors[COL_ATTACH],
                detachment=curr_factors[COL_DETACH],
                w=curr_factors[COL_W],
                p=curr_factors[COL_P],
            )

            delta_rw = rw_new - rw_prev
            shapley_sums[f] += delta_rw

            rw_prev = rw_new

    effects = {
        f"{f}_shapley_effect": (shapley_sums[f] / n_perm) * ead4
        for f in FACTOR_LIST
    }

    return pd.Series(effects)


# ======================================
# PURE (COUNTERFACTUAL) FACTOR EFFECT PER CUSIP
# ======================================

def factor_pure_effects_row(row: pd.Series) -> pd.Series:
    """
    PURE / counterfactual factor effect:

    Start: all factors at Q3.
    For each factor f: change only f to its Q4 level, keep others at Q3.
    EAD = EAD_Q4.

    ΔRWA_f_pure = [ RW(Q3 with f=Q4) − RW(Q3) ] * EAD_Q4
    """
    ead4 = row[f"{COL_EAD}_Q4"]

    if pd.isna(ead4) or ead4 == 0:
        return pd.Series({f"{f}_pure_effect": 0.0 for f in FACTOR_LIST})

    factors_q3 = {
        COL_KG:      row.get(f"{COL_KG}_Q3"),
        COL_ATTACH:  row.get(f"{COL_ATTACH}_Q3"),
        COL_DETACH:  row.get(f"{COL_DETACH}_Q3"),
        COL_W:       row.get(f"{COL_W}_Q3"),
        COL_P:       row.get(f"{COL_P}_Q3"),
    }
    factors_q4 = {
        COL_KG:      row.get(f"{COL_KG}_Q4"),
        COL_ATTACH:  row.get(f"{COL_ATTACH}_Q4"),
        COL_DETACH:  row.get(f"{COL_DETACH}_Q4"),
        COL_W:       row.get(f"{COL_W}_Q4"),
        COL_P:       row.get(f"{COL_P}_Q4"),
    }

    for f in FACTOR_LIST:
        if pd.isna(factors_q3[f]):
            factors_q3[f] = 0.0
        if pd.isna(factors_q4[f]):
            factors_q4[f] = 0.0

    rw_q3 = compute_rw_from_factors(
        kg=factors_q3[COL_KG],
        attachment=factors_q3[COL_ATTACH],
        detachment=factors_q3[COL_DETACH],
        w=factors_q3[COL_W],
        p=factors_q3[COL_P],
    )

    effects = {}

    for f in FACTOR_LIST:
        curr = factors_q3.copy()
        curr[f] = factors_q4[f]

        rw_cf = compute_rw_from_factors(
            kg=curr[COL_KG],
            attachment=curr[COL_ATTACH],
            detachment=curr[COL_DETACH],
            w=curr[COL_W],
            p=curr[COL_P],
        )

        delta_rw = rw_cf - rw_q3
        effects[f"{f}_pure_effect"] = delta_rw * ead4

    return pd.Series(effects)


# ==========================
# MAIN LOGIC
# ==========================

def main():
    # 1. Read inputs
    df_q3_raw = read_input(INPUT_Q3_PATH)
    df_q4_raw = read_input(INPUT_Q4_PATH)

    # 2. Aggregate by CUSIP
    df_q3 = aggregate_by_cusip(df_q3_raw, "Q3")
    df_q4 = aggregate_by_cusip(df_q4_raw, "Q4")

    # 3. Merge Q3 and Q4 by CUSIP
    df = df_q3.merge(df_q4, on=COL_CUSIP, how="outer", indicator=True)

    # Asset class (constant per CUSIP)
    df[COL_ASSET_CLASS] = df[f"{COL_ASSET_CLASS}_Q3"].combine_first(
        df[f"{COL_ASSET_CLASS}_Q4"]
    )

    # Status: new / gone / common
    df["status"] = df["_merge"].map(
        {
            "left_only": "gone",
            "right_only": "new",
            "both": "common",
        }
    )

    # 4. Totals
    total_rwa_q3 = df[f"{COL_RWA}_Q3"].sum(skipna=True)
    total_rwa_q4 = df[f"{COL_RWA}_Q4"].sum(skipna=True)
    delta_rwa_total = total_rwa_q4 - total_rwa_q3

    # 5. Masks
    mask_new = df["_merge"] == "right_only"
    mask_gone = df["_merge"] == "left_only"
    mask_common = df["_merge"] == "both"

    # RW from data (for all rows; for new/gone will be 0/NaN handled)
    df["RW_Q3_from_data"] = df[f"{COL_RWA}_Q3"] / df[f"{COL_EAD}_Q3"]
    df["RW_Q4_from_data"] = df[f"{COL_RWA}_Q4"] / df[f"{COL_EAD}_Q4"]
    df["RW_Q3_from_data"] = df["RW_Q3_from_data"].replace(
        [np.inf, -np.inf], 0
    ).fillna(0)
    df["RW_Q4_from_data"] = df["RW_Q4_from_data"].replace(
        [np.inf, -np.inf], 0
    ).fillna(0)

    # 6. New / gone effects
    new_papers_effect = df.loc[mask_new, f"{COL_RWA}_Q4"].sum(skipna=True)
    gone_papers_effect = -df.loc[mask_gone, f"{COL_RWA}_Q3"].sum(skipna=True)

    # 7. Common CUSIPs
    common = df.loc[mask_common].copy()

    # Exposure effect (only common)
    common["exposure_effect"] = common["RW_Q3_from_data"] * (
        common[f"{COL_EAD}_Q4"] - common[f"{COL_EAD}_Q3"]
    )
    exposure_effect_existing = common["exposure_effect"].sum(skipna=True)

    # Shapley (only common)
    shapley_df = common.apply(factor_shapley_effects_row, axis=1)
    for col in shapley_df.columns:
        common[col] = shapley_df[col]

    shapley_sums = {col: common[col].sum(skipna=True) for col in shapley_df.columns}
    total_shapley_effect = sum(shapley_sums.values())

    # Pure (only common)
    pure_df = common.apply(factor_pure_effects_row, axis=1)
    for col in pure_df.columns:
        common[col] = pure_df[col]

    pure_sums = {col: common[col].sum(skipna=True) for col in pure_df.columns}
    total_pure_effect = sum(pure_sums.values())

    # ==========================
    # BUSINESS VIEW: "WHAT CHANGED?"
    # ==========================
    # If factor_Q3 == factor_Q4 -> business_effect = 0,
    # otherwise business_effect = shapley/pure_effect.
    for f in FACTOR_LIST:
        col_q3 = f"{f}_Q3"
        col_q4 = f"{f}_Q4"
        col_shapley = f"{f}_shapley_effect"
        col_pure = f"{f}_pure_effect"

        changed_mask = common[col_q3] != common[col_q4]

        common[f"{f}_shapley_business"] = np.where(
            changed_mask, common[col_shapley], 0.0
        )
        common[f"{f}_pure_business"] = np.where(
            changed_mask, common[col_pure], 0.0
        )

    shapley_business_sums = {
        f"{f}_shapley_business": common[f"{f}_shapley_business"].sum(skipna=True)
        for f in FACTOR_LIST
    }
    pure_business_sums = {
        f"{f}_pure_business": common[f"{f}_pure_business"].sum(skipna=True)
        for f in FACTOR_LIST
    }

    total_shapley_business = sum(shapley_business_sums.values())
    total_pure_business = sum(pure_business_sums.values())

    # 8. ΔEAD, ΔRWA, ΔRW (for all CUSIPs)
    df["delta_ead"] = df[f"{COL_EAD}_Q4"] - df[f"{COL_EAD}_Q3"]
    df["delta_rwa"] = df[f"{COL_RWA}_Q4"] - df[f"{COL_RWA}_Q3"]
    df["delta_rw"] = df["RW_Q4_from_data"] - df["RW_Q3_from_data"]

    # 9. Global decomposition
    total_explained = (
        new_papers_effect
        + gone_papers_effect
        + exposure_effect_existing
        + total_shapley_effect
    )
    unexplained = delta_rwa_total - total_explained

    # ==========================
    # GLOBAL SUMMARY (print)
    # ==========================

    print("===== RWA ATTRIBUTION (SSFA) – TOTAL PORTFOLIO =====")
    print(f"Total RWA Q3: {total_rwa_q3:,.2f}")
    print(f"Total RWA Q4: {total_rwa_q4:,.2f}")
    print(f"ΔRWA (Q4 - Q3): {delta_rwa_total:,.2f}")
    print()
    print("Contributions (signed, Shapley for factors):")
    print(f"  New:       {new_papers_effect:,.2f}")
    print(f"  Gone:      {gone_papers_effect:,.2f}")
    print(f"  Exposure:  {exposure_effect_existing:,.2f}")
    print(f"  Factors:   {total_shapley_effect:,.2f}")
    print(f"  Explained: {total_explained:,.2f}")
    print(f"  Unexpl.:   {unexplained:,.2f}")
    print()

    print("Factor effects – Shapley (total portfolio):")
    for f in FACTOR_LIST:
        key = f"{f}_shapley_effect"
        print(f"    {f:12s}: {shapley_sums.get(key, 0.0):,.2f}")
    print()

    print("Factor effects – PURE (total portfolio):")
    for f in FACTOR_LIST:
        key = f"{f}_pure_effect"
        print(f"    {f:12s}: {pure_sums.get(key, 0.0):,.2f}")
    print()

    print("Factor effects – Shapley BUSINESS view (only changed factors):")
    for f in FACTOR_LIST:
        key = f"{f}_shapley_business"
        print(f"    {f:12s}: {shapley_business_sums.get(key, 0.0):,.2f}")
    print()

    print("Factor effects – PURE BUSINESS view (only changed factors):")
    for f in FACTOR_LIST:
        key = f"{f}_pure_business"
        print(f"    {f:12s}: {pure_business_sums.get(key, 0.0):,.2f}")
    print()

    # ==========================
    # BY ASSET CLASS
    # ==========================

    asset_classes = df[COL_ASSET_CLASS].dropna().unique()
    asset_classes = sorted(asset_classes)

    results_by_class = []

    for cls in asset_classes:
        sub_all = df[df[COL_ASSET_CLASS] == cls]
        total_rwa_q3_cls = sub_all[f"{COL_RWA}_Q3"].sum(skipna=True)
        total_rwa_q4_cls = sub_all[f"{COL_RWA}_Q4"].sum(skipna=True)
        delta_rwa_cls = total_rwa_q4_cls - total_rwa_q3_cls

        new_eff_cls = sub_all.loc[sub_all["status"] == "new", f"{COL_RWA}_Q4"].sum(
            skipna=True
        )
        gone_eff_cls = -sub_all.loc[sub_all["status"] == "gone", f"{COL_RWA}_Q3"].sum(
            skipna=True
        )

        common_cls = common[common[COL_ASSET_CLASS] == cls]
        exposure_eff_cls = common_cls["exposure_effect"].sum(skipna=True)

        shapley_cls_sums = {
            f"{f}_shapley_effect": common_cls[f"{f}_shapley_effect"].sum(skipna=True)
            for f in FACTOR_LIST
        }
        shapley_cls_total = sum(shapley_cls_sums.values())

        pure_cls_sums = {
            f"{f}_pure_effect": common_cls[f"{f}_pure_effect"].sum(skipna=True)
            for f in FACTOR_LIST
        }
        pure_cls_total = sum(pure_cls_sums.values())

        shapley_cls_business_sums = {
            f"{f}_shapley_business": common_cls[f"{f}_shapley_business"].sum(
                skipna=True
            )
            for f in FACTOR_LIST
        }
        pure_cls_business_sums = {
            f"{f}_pure_business": common_cls[f"{f}_pure_business"].sum(skipna=True)
            for f in FACTOR_LIST
        }

        shapley_cls_business_total = sum(shapley_cls_business_sums.values())
        pure_cls_business_total = sum(pure_cls_business_sums.values())

        explained_cls = (
            new_eff_cls + gone_eff_cls + exposure_eff_cls + shapley_cls_total
        )
        unexplained_cls = delta_rwa_cls - explained_cls

        results_by_class.append(
            {
                "asset_class": cls,
                "total_rwa_q3": total_rwa_q3_cls,
                "total_rwa_q4": total_rwa_q4_cls,
                "delta_rwa": delta_rwa_cls,
                "new": new_eff_cls,
                "gone": gone_eff_cls,
                "exposure": exposure_eff_cls,
                "factor_shapley": shapley_cls_total,
                "factor_pure": pure_cls_total,
                "factor_shapley_business": shapley_cls_business_total,
                "factor_pure_business": pure_cls_business_total,
                "explained": explained_cls,
                "unexplained": unexplained_cls,
                **{
                    f"{f}_shapley": shapley_cls_sums[f"{f}_shapley_effect"]
                    for f in FACTOR_LIST
                },
                **{
                    f"{f}_pure": pure_cls_sums[f"{f}_pure_effect"]
                    for f in FACTOR_LIST
                },
                **{
                    f"{f}_shapley_bus": shapley_cls_business_sums[
                        f"{f}_shapley_business"
                    ]
                    for f in FACTOR_LIST
                },
                **{
                    f"{f}_pure_bus": pure_cls_business_sums[f"{f}_pure_business"]
                    for f in FACTOR_LIST
                },
            }
        )

        # Short print per class
        print(f"--- asset_class = {cls} ---")
        print(
            f"RWA Q3: {total_rwa_q3_cls:,.2f} | "
            f"RWA Q4: {total_rwa_q4_cls:,.2f} | "
            f"ΔRWA: {delta_rwa_cls:,.2f}"
        )
        print(f"  New:       {new_eff_cls:,.2f}")
        print(f"  Gone:      {gone_eff_cls:,.2f}")
        print(f"  Exposure:  {exposure_eff_cls:,.2f}")
        print(f"  Factors:   {shapley_cls_total:,.2f}")
        print(f"  Explained: {explained_cls:,.2f}")
        print(f"  Unexpl.:   {unexplained_cls:,.2f}")
        print()

    df_results_by_class = pd.DataFrame(results_by_class)

    # ==========================
    # PER-CUSIP EXPORT
    # ==========================

    # Inject common effects back into df (by CUSIP)
    effects_cols = (
        ["exposure_effect"]
        + [f"{f}_shapley_effect" for f in FACTOR_LIST]
        + [f"{f}_pure_effect" for f in FACTOR_LIST]
        + [f"{f}_shapley_business" for f in FACTOR_LIST]
        + [f"{f}_pure_business" for f in FACTOR_LIST]
    )
    common_effects = common[[COL_CUSIP] + effects_cols].copy()

    df = df.merge(common_effects, on=COL_CUSIP, how="left", suffixes=("", "_from_common"))

    # Columns for per-CUSIP output
    per_cusip_cols = (
        [
            COL_CUSIP,
            COL_ASSET_CLASS,
            "status",
            f"{COL_EAD}_Q3",
            f"{COL_EAD}_Q4",
            "delta_ead",
            f"{COL_RWA}_Q3",
            f"{COL_RWA}_Q4",
            "delta_rwa",
            "RW_Q3_from_data",
            "RW_Q4_from_data",
            "delta_rw",
            "exposure_effect",
        ]
        + [f"{f}_shapley_effect" for f in FACTOR_LIST]
        + [f"{f}_pure_effect" for f in FACTOR_LIST]
        + [f"{f}_shapley_business" for f in FACTOR_LIST]
        + [f"{f}_pure_business" for f in FACTOR_LIST]
    )

    # A) Only common CUSIPs
    df_cusip_common = df[df["status"] == "common"][per_cusip_cols].copy()

    # B) All CUSIPs
    df_cusip_all = df[per_cusip_cols].copy()

    # ==========================
    # SAVE TO EXCEL
    # ==========================

    # 1) By asset class
    with pd.ExcelWriter("rwa_attr_by_asset_class.xlsx") as writer:
        df_results_by_class.to_excel(writer, sheet_name="by_asset_class", index=False)

    # 2) Per-CUSIP: common only
    with pd.ExcelWriter("rwa_attr_per_cusip_common.xlsx") as writer:
        df_cusip_common.to_excel(writer, sheet_name="common_only", index=False)

    # 3) Per-CUSIP: all CUSIPs
    with pd.ExcelWriter("rwa_attr_per_cusip_all.xlsx") as writer:
        df_cusip_all.to_excel(writer, sheet_name="all_cusips", index=False)

    print("\nFiles saved:")
    print(" - rwa_attr_by_asset_class.xlsx")
    print(" - rwa_attr_per_cusip_common.xlsx")
    print(" - rwa_attr_per_cusip_all.xlsx")


if __name__ == "__main__":
    main()
