import pandas as pd
import numpy as np

def issuer_limit_monitor(
    DF: pd.DataFrame,
    IssuerLimits: pd.DataFrame,
    exception_limits: dict | None = None,
    exposure_col: str = "Exposure(USD)",
    issuer_col: str = "MM_ISSUER",
    rating_col: str = "Lowest_Bucket_Rating",
    subasset_col: str = "Sub_Asset_Class",
):
    """
    Returns:
      - issuer_detail: one row per issuer with exposure, rating, base limit, exception limit, effective limit, utilization, breach flag
      - subasset_summary: Sub_Asset_Class | Count of Issuer | Max Exposure (+ optional fields)
    """

    # ---- checks ----
    req_df = {issuer_col, rating_col, subasset_col, exposure_col}
    req_lim = {rating_col, "IssuerLimit", "MasterTrustLimit"}
    missing_df = req_df - set(DF.columns)
    missing_lim = req_lim - set(IssuerLimits.columns)
    if missing_df:
        raise SystemExit(f"Critical Error: DF missing columns: {sorted(missing_df)}")
    if missing_lim:
        raise SystemExit(f"Critical Error: IssuerLimits missing columns: {sorted(missing_lim)}")

    df = DF.copy()
    lim = IssuerLimits.copy()

    # normalize strings to avoid merge mismatches
    for c in [issuer_col, rating_col, subasset_col]:
        df[c] = df[c].astype("string").str.strip()
    lim[rating_col] = lim[rating_col].astype("string").str.strip()

    df[exposure_col] = pd.to_numeric(df[exposure_col], errors="coerce").fillna(0.0)
    lim["IssuerLimit"] = pd.to_numeric(lim["IssuerLimit"], errors="coerce")
    lim["MasterTrustLimit"] = pd.to_numeric(lim["MasterTrustLimit"], errors="coerce")

    # ---- issuer-level aggregation ----
    # If issuer appears in multiple Sub_Asset_Class, we assign the one with max exposure (so summary is stable)
    issuer_subasset = (
        df.groupby([issuer_col, subasset_col], dropna=False)[exposure_col].sum()
          .reset_index()
          .sort_values([issuer_col, exposure_col], ascending=[True, False], kind="stable")
          .drop_duplicates(subset=[issuer_col])
          [[issuer_col, subasset_col]]
    )

    issuer_exposure = (
        df.groupby(issuer_col, dropna=False)[exposure_col].sum()
          .reset_index()
          .rename(columns={exposure_col: "IssuerExposure"})
    )

    # Rating per issuer: take the first non-null rating seen (and warn later if inconsistent)
    issuer_rating = (
        df[[issuer_col, rating_col]]
        .dropna(subset=[rating_col])
        .drop_duplicates()
        .groupby(issuer_col, dropna=False)[rating_col]
        .agg(lambda s: s.iloc[0])   # first
        .reset_index()
    )

    issuer_detail = (
        issuer_exposure
        .merge(issuer_subasset, on=issuer_col, how="left")
        .merge(issuer_rating, on=issuer_col, how="left")
        .merge(lim[[rating_col, "IssuerLimit", "MasterTrustLimit"]], on=rating_col, how="left")
    )

    # ---- exceptions ----
    exception_limits = exception_limits or {}
    exc = pd.Series(exception_limits, name="ExceptionLimit")
    exc.index.name = issuer_col
    exc = exc.reset_index()
    exc["ExceptionLimit"] = pd.to_numeric(exc["ExceptionLimit"], errors="coerce")

    issuer_detail = issuer_detail.merge(exc, on=issuer_col, how="left")

    # effective limit: ExceptionLimit if provided else IssuerLimit
    issuer_detail["EffectiveIssuerLimit"] = issuer_detail["ExceptionLimit"].combine_first(issuer_detail["IssuerLimit"])

    issuer_detail["Utilization"] = np.where(
        pd.to_numeric(issuer_detail["EffectiveIssuerLimit"], errors="coerce").fillna(0.0) > 0,
        issuer_detail["IssuerExposure"] / issuer_detail["EffectiveIssuerLimit"],
        np.nan
    )

    issuer_detail["Breach"] = np.where(issuer_detail["Utilization"] >= 1, 1, 0)

    # ---- optional data quality check: issuer has multiple ratings in DF ----
    rating_counts = (
        df[[issuer_col, rating_col]]
        .dropna(subset=[rating_col])
        .drop_duplicates()
        .groupby(issuer_col)[rating_col].nunique()
        .reset_index(name="DistinctRatings")
    )
    issuer_detail = issuer_detail.merge(rating_counts, on=issuer_col, how="left")
    issuer_detail["DistinctRatings"] = issuer_detail["DistinctRatings"].fillna(0).astype(int)

    # ---- summary by Sub_Asset_Class (as requested) ----
    subasset_summary = (
        issuer_detail.groupby(subasset_col, dropna=False)
        .agg(
            **{
                "Count of Issuer": (issuer_col, "nunique"),
                "Max Exposure": ("IssuerExposure", "max"),
                # optional extras (keep if you want)
                "Breaches": ("Breach", "sum"),
                "Max Utilization": ("Utilization", "max"),
            }
        )
        .reset_index()
        .rename(columns={subasset_col: "Sub_Asset_Class"})
        .sort_values(["Max Utilization", "Max Exposure"], ascending=[False, False], kind="stable")
    )

    return issuer_detail, subasset_summary

issuer_detail, subasset_summary = issuer_limit_monitor(DF, IssuerLimits)

exception_limits = {
    "Issuer A": 250_000_000,  # override IssuerLimit for this issuer
    "Issuer B": 100_000_000,
}

issuer_detail, subasset_summary = issuer_limit_monitor(
    DF, IssuerLimits, exception_limits=exception_limits
)
