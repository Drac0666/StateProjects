# transition_matrix_with_totals.py
# Python 3.9

from __future__ import annotations
import pandas as pd
from pathlib import Path
from typing import List, Tuple
import re

# === CONFIG: set your files here ===
FILE_T0 = r"C:\path\to\ratings_05-30.xlsx"   # earlier date
FILE_T1 = r"C:\path\to\ratings_08-29.xlsx"   # later date
SHEET_NAME = "Holdings"
ID_COL = "Identifier"
RATING_COL = "Lowest Rating"

# Target order (add "D" if you also track defaults)
RATING_ORDER: List[str] = ["AAA", "AA", "A", "BBB", "BB", "B", "CCC", "CC", "C"]

# ---------- Helpers ----------

def bucketize(raw: str) -> str:
    """Map raw rating strings to coarse buckets (handles +/- and Moodyâ€™s styles)."""
    if raw is None or str(raw).strip() == "":
        return None
    s = str(raw).strip().upper()
    s = s.replace(" ", "").replace("+", "").replace("-", "")

    # Not rated / placeholders
    if s in {"NR", "N/R", "NOTRATED", "NA"}:
        return None

    # Direct buckets after +/- removal
    if s in {"AAA", "AA", "A", "BBB", "BB", "B", "CCC", "CC", "C"}:
        return s

    # Moody's mapping (accept numeric modifiers)
    moody_patterns = [
        (r"AAA", "AAA"),                 # Aaa -> AAA (after upper/cleanup often becomes AAA)
        (r"AA[123]?", "AA"),             # Aa1/Aa2/Aa3 -> AA
        (r"A[123]?", "A"),               # A1/A2/A3 -> A
        (r"BAA[123]?", "BBB"),           # Baa1/2/3 -> BBB
        (r"BA[123]?", "BB"),             # Ba1/2/3 -> BB
        (r"B[123]?", "B"),               # B1/2/3 -> B
        (r"CAA[123]?", "CCC"),           # Caa1/2/3 -> CCC
        (r"CA", "CC"),                   # Ca -> CC
        (r"CCC", "CCC"),
        (r"CC", "CC"),
        (r"C", "C"),
    ]
    for pat, bucket in moody_patterns:
        if re.fullmatch(pat, s):
            return bucket

    # 'D' / 'DEFAULT' if you decide to include it
    if re.fullmatch(r"(D|DEF(AULT)?)", s) and "D" in RATING_ORDER:
        return "D"

    return None

def load_sheet(path: str) -> pd.DataFrame:
    df = pd.read_excel(path, sheet_name=SHEET_NAME, dtype=str, usecols=[ID_COL, RATING_COL])
    df.columns = [c.strip() for c in df.columns]
    df[ID_COL] = df[ID_COL].astype(str).str.strip()
    df["bucket"] = df[RATING_COL].map(bucketize)
    df = df.dropna(subset=[ID_COL, "bucket"])

    # If duplicates: keep the WORST (lowest) by our order
    order = {r: i for i, r in enumerate(RATING_ORDER)}
    df = (
        df.sort_values(by=["bucket"], key=lambda s: s.map(order))
          .drop_duplicates(subset=[ID_COL], keep="last")
          [[ID_COL, "bucket"]]
    )
    return df

def transition_counts_with_extras(t0: pd.DataFrame, t1: pd.DataFrame):
    # Common IDs for transitions
    common = t0.merge(t1, on=ID_COL, how="inner", suffixes=("_t0", "_t1"))
    counts = pd.crosstab(common["bucket_t0"], common["bucket_t1"]).reindex(
        index=RATING_ORDER, columns=RATING_ORDER, fill_value=0
    )

    # Paid Off: present in T0, gone in T1
    disappeared = t0[~t0[ID_COL].isin(t1[ID_COL])]
    paid_off = disappeared.groupby("bucket")[ID_COL].nunique().reindex(RATING_ORDER).fillna(0).astype(int)

    # New Securities: present in T1, absent in T0
    newcomers = t1[~t1[ID_COL].isin(t0[ID_COL])]
    new_by_to = newcomers.groupby("bucket")[ID_COL].nunique().reindex(RATING_ORDER).fillna(0).astype(int)

    # Starting and Ending
    starting = t0.groupby("bucket")[ID_COL].nunique().reindex(RATING_ORDER).fillna(0).astype(int)
    ending   = t1.groupby("bucket")[ID_COL].nunique().reindex(RATING_ORDER).fillna(0).astype(int)

    return counts, paid_off, new_by_to, starting, ending

def build_outputs(file_t0: str, file_t1: str, out_prefix: str = "transition_matrix"):
    t0 = load_sheet(file_t0)
    t1 = load_sheet(file_t1)

    counts, paid_off, new_securities, starting, ending = transition_counts_with_extras(t0, t1)

    # --- Build COUNTS table with requested column order ---
    # Order: Starting | [AAA..C] | Paid Off | New Securities | Ending
    cols_transition = RATING_ORDER
    counts_ext = counts.reindex(columns=cols_transition, fill_value=0).copy()
    counts_ext.insert(0, "Starting", starting)                # first column
    counts_ext["Paid Off"] = paid_off
    counts_ext["New Securities"] = new_securities
    counts_ext["Ending"] = ending

    # Add bottom 'Total' row = column-wise totals (securities total per column)
    totals = counts_ext.sum(axis=0, numeric_only=True)
    counts_ext.loc["Total"] = totals

    # --- Percent matrix (row-normalized by Starting). Keep same column order. ---
    denom = counts.sum(axis=1).add(paid_off, fill_value=0)  # equals Starting
    pct = counts.reindex(columns=cols_transition, fill_value=0).div(denom.replace(0, 1), axis=0) * 100.0
    pct = pct.round(2)
    pct_ext = pct.copy()
    pct_ext.insert(0, "Starting", starting)                 # counts for reference
    pct_ext["Paid Off"] = (paid_off / denom.replace(0, 1) * 100.0).round(2)
    pct_ext["New Securities"] = ""                          # not a T0 transition
    pct_ext["Ending"] = ending                              # counts for reference
    # No 'Total' row on percent sheet (summing % down a column isn't meaningful)

    # Save CSVs
    counts_ext.to_csv(f"{out_prefix}_counts.csv")
    pct_ext.to_csv(f"{out_prefix}_pct.csv")

    # Save Excel with bold diagonal in % sheet
    with pd.ExcelWriter(f"{out_prefix}.xlsx", engine="xlsxwriter") as xw:
        counts_ext.to_excel(xw, sheet_name="counts")
        pct_ext.to_excel(xw, sheet_name="percent")

        wb = xw.book
        bold = wb.add_format({"bold": True})
        ws = xw.sheets["percent"]
        n = len(RATING_ORDER)
        # Bold only the diagonal of the transition area (skip 'Starting' col)
        for i in range(n):
            # Row i starts at Excel row 2 (headers row 1), transition cols start at col 2 (col A is 'Starting')
            ws.write(i+2, i+2, pct_ext.iloc[i, i+1], bold)

    print("Outputs:", f"{out_prefix}_counts.csv", f"{out_prefix}_pct.csv", f"{out_prefix}.xlsx")

if __name__ == "__main__":
    out_name = Path(FILE_T0).stem + "_to_" + Path(FILE_T1).stem
    build_outputs(FILE_T0, FILE_T1, out_prefix=out_name)
