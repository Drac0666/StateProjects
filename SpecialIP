# transition_matrix_with_paidoff_new_start_end.py
# Python 3.9

from __future__ import annotations
import pandas as pd
from pathlib import Path
from typing import List, Tuple
import re

# === CONFIG: set your files here ===
FILE_T0 = r"C:\path\to\ratings_05-30.xlsx"   # earlier date
FILE_T1 = r"C:\path\to\ratings_08-29.xlsx"   # later date
SHEET_NAME = "Holdings"
ID_COL = "Identifier"
RATING_COL = "Lowest Rating"

# Target order (add "D" if you also track defaults)
RATING_ORDER: List[str] = ["AAA", "AA", "A", "BBB", "BB", "B", "CCC", "CC", "C"]

# ---------- Helpers ----------

def bucketize(raw: str) -> str:
    """Map raw rating strings to coarse buckets in RATING_ORDER.
       Handles +/- (AA+, AA- → AA), Moody’s (Aaa, Aa2, Baa3, Caa1, Ca), etc.
    """
    if raw is None or str(raw).strip() == "":
        return None
    s = str(raw).strip().upper()
    s = s.replace(" ", "").replace("+", "").replace("-", "")

    # Not rated / placeholders
    if s in {"NR", "N/R", "NOTRATED", "NA"}:
        return None

    # Direct buckets after +/- removal
    if s in {"AAA", "AA", "A", "BBB", "BB", "B", "CCC", "CC", "C"}:
        return s

    # Moody's mapping with optional numeric modifiers 1/2/3
    moody_patterns = [
        (r"AAA", "AAA"),                 # Aaa (after upper/cleanup often becomes AAA)
        (r"AA[123]?", "AA"),             # Aa1/Aa2/Aa3
        (r"A[123]?", "A"),               # A1/A2/A3
        (r"BAA[123]?", "BBB"),           # Baa1/2/3
        (r"BA[123]?", "BB"),             # Ba1/2/3
        (r"B[123]?", "B"),               # B1/2/3
        (r"CAA[123]?", "CCC"),           # Caa1/2/3
        (r"CA", "CC"),                   # Ca
        (r"CCC", "CCC"),
        (r"CC", "CC"),
        (r"C", "C"),
    ]
    for pat, bucket in moody_patterns:
        if re.fullmatch(pat, s):
            return bucket

    # 'D' / 'DEFAULT' if included in RATING_ORDER
    if re.fullmatch(r"(D|DEF(AULT)?)", s) and "D" in RATING_ORDER:
        return "D"

    return None

def load_sheet(path: str) -> pd.DataFrame:
    df = pd.read_excel(path, sheet_name=SHEET_NAME, dtype=str, usecols=[ID_COL, RATING_COL])
    df.columns = [c.strip() for c in df.columns]
    df[ID_COL] = df[ID_COL].astype(str).str.strip()
    df["bucket"] = df[RATING_COL].map(bucketize)
    df = df.dropna(subset=[ID_COL, "bucket"])

    # If duplicates: keep the WORST (lowest) by our order
    order = {r: i for i, r in enumerate(RATING_ORDER)}
    df = (
        df.sort_values(by=["bucket"], key=lambda s: s.map(order))
          .drop_duplicates(subset=[ID_COL], keep="last")
          [[ID_COL, "bucket"]]
    )
    return df

def transition_counts_with_extras(t0: pd.DataFrame, t1: pd.DataFrame):
    # Common IDs for transitions
    common = t0.merge(t1, on=ID_COL, how="inner", suffixes=("_t0", "_t1"))
    counts = pd.crosstab(common["bucket_t0"], common["bucket_t1"]).reindex(
        index=RATING_ORDER, columns=RATING_ORDER, fill_value=0
    )

    # Paid Off: present in T0, gone in T1
    disappeared = t0[~t0[ID_COL].isin(t1[ID_COL])]
    paid_off = disappeared.groupby("bucket")[ID_COL].nunique().rein_]()_
