# transition_matrix_with_visuals.py
# Python 3.9

from __future__ import annotations
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from typing import List, Tuple
import re

# === CONFIG: set your files here ===
FILE_T0 = r"C:\path\to\ratings_05-30.xlsx"   # earlier date
FILE_T1 = r"C:\path\to\ratings_08-29.xlsx"   # later date
SHEET_NAME = "Holdings"
ID_COL = "Identifier"
RATING_COL = "Lowest Rating"

# Buckets (best -> worst). Add "D" if you track defaults.
RATING_ORDER: List[str] = ["AAA", "AA", "A", "BBB", "BB", "B", "CCC", "CC", "C"]

# ---------- Helpers ----------
def bucketize(raw: str) -> str:
    if raw is None or str(raw).strip() == "":
        return None
    s = str(raw).strip().upper()
    s = s.replace(" ", "").replace("+", "").replace("-", "")
    if s in {"NR", "N/R", "NOTRATED", "NA"}:
        return None
    if s in {"AAA", "AA", "A", "BBB", "BB", "B", "CCC", "CC", "C"}:
        return s
    moody_patterns = [
        (r"AAA", "AAA"),
        (r"AA[123]?", "AA"),
        (r"A[123]?", "A"),
        (r"BAA[123]?", "BBB"),
        (r"BA[123]?", "BB"),
        (r"B[123]?", "B"),
        (r"CAA[123]?", "CCC"),
        (r"CA", "CC"),
        (r"CCC", "CCC"),
        (r"CC", "CC"),
        (r"C", "C"),
    ]
    for pat, bucket in moody_patterns:
        if re.fullmatch(pat, s):
            return bucket
    if re.fullmatch(r"(D|DEF(AULT)?)", s) and "D" in RATING_ORDER:
        return "D"
    return None

def load_sheet(path: str) -> pd.DataFrame:
    df = pd.read_excel(path, sheet_name=SHEET_NAME, dtype=str, usecols=[ID_COL, RATING_COL])
    df.columns = [c.strip() for c in df.columns]
    df[ID_COL] = df[ID_COL].astype(str).str.strip()
    df["bucket"] = df[RATING_COL].map(bucketize)
    df = df.dropna(subset=[ID_COL, "bucket"])
    order = {r: i for i, r in enumerate(RATING_ORDER)}
    df = (
        df.sort_values(by=["bucket"], key=lambda s: s.map(order))
          .drop_duplicates(subset=[ID_COL], keep="last")
          [[ID_COL, "bucket"]]
    )
    return df

def compute_blocks(t0: pd.DataFrame, t1: pd.DataFrame):
    common = t0.merge(t1, on=ID_COL, how="inner", suffixes=("_t0", "_t1"))
    counts = pd.crosstab(common["bucket_t0"], common["bucket_t1"]).reindex(
        index=RATING_ORDER, columns=RATING_ORDER, fill_value=0
    )

    disappeared = t0[~t0[ID_COL].isin(t1[ID_COL])]
    paid_off = disappeared.groupby("bucket")[ID_COL].nunique().reindex(RATING_ORDER).fillna(0).astype(int)

    newcomers = t1[~t1[ID_COL].isin(t0[ID_COL])]
    new_by_to = newcomers.groupby("bucket")[ID_COL].nunique().reindex(RATING_ORDER).fillna(0).astype(int)

    starting = t0.groupby("bucket")[ID_COL].nunique().reindex(RATING_ORDER).fillna(0).astype(int)
    ending   = t1.groupby("bucket")[ID_COL].nunique().reindex(RATING_ORDER).fillna(0).astype(int)

    return counts, paid_off, new_by_to, starting, ending

# ---------- Visualization ----------
def plot_heatmap(matrix: pd.DataFrame, title: str, outpath: Path):
    fig, ax = plt.subplots(figsize=(10, 7))
    # Heatmap with default colormap; values annotated
    im = ax.imshow(matrix.values)
    ax.set_xticks(range(matrix.shape[1]))
    ax.set_yticks(range(matrix.shape[0]))
    ax.set_xticklabels(matrix.columns, rotation=45, ha="right")
    ax.set_yticklabels(matrix.index)
    ax.set_title(title)
    ax.set_xlabel("To bucket")
    ax.set_ylabel("From bucket")
    # annotate
    for i in range(matrix.shape[0]):
        for j in range(matrix.shape[1]):
            ax.text(j, i, f"{matrix.iat[i,j]:g}", ha="center", va="center")
    fig.tight_layout()
    fig.savefig(outpath, dpi=200, bbox_inches="tight")
    plt.close(fig)

def plot_row_stacked_percent(pct_matrix: pd.DataFrame, title: str, outpath: Path):
    # Show composition per 'from' bucket (each row sums to 100)
    fig, ax = plt.subplots(figsize=(11, 6))
    y = range(len(pct_matrix.index))
    left = [0.0] * len(pct_matrix.index)
    for col in pct_matrix.columns:
        vals = pct_matrix[col].values
        ax.barh(y, vals, left=left)
        left = [l + v for l, v in zip(left, vals)]
    ax.set_yticks(list(y))
    ax.set_yticklabels(pct_matrix.index)
    ax.set_xlabel("Share of cohort (%)")
    ax.set_title(title)
    ax.invert_yaxis()  # top = best rating
    fig.tight_layout()
    fig.savefig(outpath, dpi=200, bbox_inches="tight")
    plt.close(fig)

def create_visuals(counts: pd.DataFrame,
                   paid_off: pd.Series,
                   starting: pd.Series,
                   out_prefix: str):
    out_base = Path(out_prefix).with_suffix("")  # drop extension if any
    # Transition % (row-normalized by Starting)
    denom = counts.sum(axis=1).add(paid_off, fill_value=0)  # equals Starting
    pct = counts.div(denom.replace(0, 1), axis=0) * 100.0
    pct = pct.reindex(index=RATING_ORDER, columns=RATING_ORDER, fill_value=0).round(2)

    # 1) Heatmap of transition counts
    plot_heatmap(
        counts.reindex(index=RATING_ORDER, columns=RATING_ORDER, fill_value=0),
        "Transition Counts (From → To)",
        out_base.with_name(out_base.name + "_heatmap_counts.png")
    )

    # 2) Heatmap of transition percentages
    plot_heatmap(
        pct,
        "Transition Percent (row = 100%, From → To)",
        out_base.with_name(out_base.name + "_heatmap_percent.png")
    )

    # 3) Stacked distribution by origin bucket
    plot_row_stacked_percent(
        pct,
        "Cohort Composition by Origin Bucket (row-normalized %)",
        out_base.with_name(out_base.name + "_stacked_composition.png")
    )

# ---------- Pipeline ----------
def run(file_t0: str, file_t1: str, out_prefix: str):
    t0 = load_sheet(file_t0)
    t1 = load_sheet(file_t1)

    counts, paid_off, new_securities, starting, ending = compute_blocks(t0, t1)

    # Build the same extended counts (for your spreadsheets) if you want to save them again:
    counts_main = counts.reindex(columns=RATING_ORDER, fill_value=0).copy()
    counts_ext = counts_main.copy()
    counts_ext.insert(0, "Starting", starting)
    counts_ext["Paid Off"] = paid_off
    counts_ext["New Securities"] = new_securities
    counts_ext["Ending"] = ending

    # CSV/Excel (optional; comment out if you only want charts)
    counts_ext.to_csv(f"{out_prefix}_counts.csv", index=True)

    with pd.ExcelWriter(f"{out_prefix}.xlsx", engine="xlsxwriter") as xw:
        counts_ext.to_excel(xw, sheet_name="counts", merge_cells=False)

    # Visuals
    create_visuals(counts_main, paid_off, starting, out_prefix)

    print("Saved:")
    print(f" - {out_prefix}_counts.csv")
    print(f" - {out_prefix}.xlsx")
    print(f" - {out_prefix}_heatmap_counts.png")
    print(f" - {out_prefix}_heatmap_percent.png")
    print(f" - {out_prefix}_stacked_composition.png")

if __name__ == "__main__":
    out_name = Path(FILE_T0).stem + "_to_" + Path(FILE_T1).stem
    run(FILE_T0, FILE_T1, out_prefix=out_name)
