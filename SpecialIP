import pandas as pd
import numpy as np
from itertools import permutations

# ==========================
# KONFIGURACJA – DO EDYCJI
# ==========================

# Ścieżki do plików wejściowych
INPUT_Q3_PATH = r"sciezka/do/pliku_Q3.csv"
INPUT_Q4_PATH = r"sciezka/do/pliku_Q4.csv"

# Typ pliku: "csv" lub "excel"
INPUT_FILE_TYPE = "csv"   # albo "excel"

# Nazwy kolumn w plikach wejściowych
COL_CUSIP      = "cusip"
COL_EAD        = "ead"
COL_RWA        = "rwa"
COL_KG         = "kg"
COL_ATTACH     = "attachment"
COL_DETACH     = "detachment"
COL_W          = "w"
COL_P          = "p"

# Lista faktorów (wygodnie w jednym miejscu)
FACTOR_LIST = [COL_KG, COL_ATTACH, COL_DETACH, COL_W, COL_P]


# ======================================
# FUNKCJA: RISK WEIGHT z SSFA z faktorów
# ======================================

def compute_rw_from_factors(kg, attachment, detachment, w, p):
    """
    TODO: WSTAW TU REALNĄ FORMUŁĘ SSFA DLA RW !!!
    Poniżej jest tylko 'placeholder', żeby skrypt się wykonywał.

    Upewnij się, że jednostki RW są spójne z tym, jak liczysz RWA:
        RWA = RW * EAD
    np. RW jako liczba typu 0.15 (15%) albo 1.25 (125%).
    """

    # ----- PRZYKŁADOWY DUMMY: ZAMIEN NA SWÓJ WZÓR -----
    # Ten dummy zwraca po prostu kg * 12.5 przycięte do 12.5
    # (to NIE jest pełna, poprawna implementacja SSFA!)
    rw = min(kg * 12.5, 12.5)
    return rw


# ==========================
# FUNKCJE POMOCNICZE
# ==========================

def read_input(path: str):
    if INPUT_FILE_TYPE.lower() == "csv":
        return pd.read_csv(path)
    elif INPUT_FILE_TYPE.lower() == "excel":
        return pd.read_excel(path)
    else:
        raise ValueError("INPUT_FILE_TYPE musi być 'csv' albo 'excel'.")


def aggregate_by_cusip(df: pd.DataFrame, period_label: str) -> pd.DataFrame:
    """
    Agregacja po CUSIP:
    - sumujemy EAD i RWA,
    - liczymy EAD-ważone średnie faktorów (kg, attachment, detachment, w, p).
    """
    cols_needed = [
        COL_CUSIP, COL_EAD, COL_RWA,
        COL_KG, COL_ATTACH, COL_DETACH, COL_W, COL_P
    ]
    missing = [c for c in cols_needed if c not in df.columns]
    if missing:
        raise KeyError(f"W pliku brakuje kolumn: {missing}")

    df = df.copy()

    # Liczniki: EAD * faktor
    for col in [COL_KG, COL_ATTACH, COL_DETACH, COL_W, COL_P]:
        df[f"{col}_num"] = df[col] * df[COL_EAD]

    grouped = df.groupby(COL_CUSIP, as_index=False).agg(
        **{
            f"{COL_EAD}_{period_label}": (COL_EAD, "sum"),
            f"{COL_RWA}_{period_label}": (COL_RWA, "sum"),
        }
    )

    num_cols = [f"{COL_KG}_num", f"{COL_ATTACH}_num", f"{COL_DETACH}_num",
                f"{COL_W}_num", f"{COL_P}_num"]
    df_num = df.groupby(COL_CUSIP, as_index=False)[num_cols].sum()

    grouped = grouped.merge(df_num, on=COL_CUSIP, how="left")

    # EAD-ważone średnie faktorów
    ead_col = f"{COL_EAD}_{period_label}"

    for col, num_col in zip(
        [COL_KG, COL_ATTACH, COL_DETACH, COL_W, COL_P],
        num_cols
    ):
        grouped[f"{col}_{period_label}"] = grouped[num_col] / grouped[ead_col]
        grouped[f"{col}_{period_label}"] = grouped[f"{col}_{period_label}"].replace(
            [np.inf, -np.inf], np.nan
        )

    grouped.drop(columns=num_cols, inplace=True)

    return grouped


# ======================================
# Shapley dla efektu faktorów per CUSIP
# ======================================

def factor_shapley_effects_row(row) -> pd.Series:
    """
    Shapley values dla efektu poszczególnych faktorów na ΔRWA
    dla pojedynczego CUSIPa.

    Start: wszystkie faktory w poziomie Q3
    Koniec: wszystkie faktory w poziomie Q4
    EAD = EAD_Q4 (efekt na docelowej ekspozycji)

    Wynik: Series z kolumnami "<factor>_shapley_effect" w jednostkach RWA.
    """
    ead4 = row[f"{COL_EAD}_Q4"]

    if pd.isna(ead4) or ead4 == 0:
        return pd.Series({f"{f}_shapley_effect": 0.0 for f in FACTOR_LIST})

    # Faktor Q3 i Q4 w słownikach
    factors_q3 = {
        COL_KG:      row.get(f"{COL_KG}_Q3"),
        COL_ATTACH:  row.get(f"{COL_ATTACH}_Q3"),
        COL_DETACH:  row.get(f"{COL_DETACH}_Q3"),
        COL_W:       row.get(f"{COL_W}_Q3"),
        COL_P:       row.get(f"{COL_P}_Q3"),
    }
    factors_q4 = {
        COL_KG:      row.get(f"{COL_KG}_Q4"),
        COL_ATTACH:  row.get(f"{COL_ATTACH}_Q4"),
        COL_DETACH:  row.get(f"{COL_DETACH}_Q4"),
        COL_W:       row.get(f"{COL_W}_Q4"),
        COL_P:       row.get(f"{COL_P}_Q4"),
    }

    # NaN → 0 (ew. możesz zmienić na inny default)
    for f in FACTOR_LIST:
        if pd.isna(factors_q3[f]):
            factors_q3[f] = 0.0
        if pd.isna(factors_q4[f]):
            factors_q4[f] = 0.0

    shapley_sums = {f: 0.0 for f in FACTOR_LIST}
    perms = list(permutations(FACTOR_LIST))
    n_perm = len(perms)

    for perm in perms:
        curr_factors = factors_q3.copy()

        rw_prev = compute_rw_from_factors(
            kg=curr_factors[COL_KG],
            attachment=curr_factors[COL_ATTACH],
            detachment=curr_factors[COL_DETACH],
            w=curr_factors[COL_W],
            p=curr_factors[COL_P],
        )

        for f in perm:
            # podmieniamy tylko jeden faktor na wartość Q4
            curr_factors[f] = factors_q4[f]

            rw_new = compute_rw_from_factors(
                kg=curr_factors[COL_KG],
                attachment=curr_factors[COL_ATTACH],
                detachment=curr_factors[COL_DETACH],
                w=curr_factors[COL_W],
                p=curr_factors[COL_P],
            )

            delta_rw = rw_new - rw_prev
            shapley_sums[f] += delta_rw

            rw_prev = rw_new

    effects = {
        f"{f}_shapley_effect": (shapley_sums[f] / n_perm) * ead4
        for f in FACTOR_LIST
    }

    return pd.Series(effects)


# ======================================
# PURE (counterfactual) efekt faktorów
# ======================================

def factor_pure_effects_row(row) -> pd.Series:
    """
    PURE / counterfactual:
    Zakładamy:
      - start: wszystkie faktory = Q3
      - zmieniamy JEDEN faktor na Q4, reszta zostaje na Q3
      - EAD = EAD_Q4

    ΔRWA_f_pure = [ RW(Q3 z f=Q4) − RW(Q3) ] * EAD_Q4
    """
    ead4 = row[f"{COL_EAD}_Q4"]

    if pd.isna(ead4) or ead4 == 0:
        return pd.Series({f"{f}_pure_effect": 0.0 for f in FACTOR_LIST})

    factors_q3 = {
        COL_KG:      row.get(f"{COL_KG}_Q3"),
        COL_ATTACH:  row.get(f"{COL_ATTACH}_Q3"),
        COL_DETACH:  row.get(f"{COL_DETACH}_Q3"),
        COL_W:       row.get(f"{COL_W}_Q3"),
        COL_P:       row.get(f"{COL_P}_Q3"),
    }
    factors_q4 = {
        COL_KG:      row.get(f"{COL_KG}_Q4"),
        COL_ATTACH:  row.get(f"{COL_ATTACH}_Q4"),
        COL_DETACH:  row.get(f"{COL_DETACH}_Q4"),
        COL_W:       row.get(f"{COL_W}_Q4"),
        COL_P:       row.get(f"{COL_P}_Q4"),
    }

    for f in FACTOR_LIST:
        if pd.isna(factors_q3[f]):
            factors_q3[f] = 0.0
        if pd.isna(factors_q4[f]):
            factors_q4[f] = 0.0

    # RW przy wszystkich faktorach z Q3
    rw_q3 = compute_rw_from_factors(
        kg=factors_q3[COL_KG],
        attachment=factors_q3[COL_ATTACH],
        detachment=factors_q3[COL_DETACH],
        w=factors_q3[COL_W],
        p=factors_q3[COL_P],
    )

    effects = {}

    for f in FACTOR_LIST:
        # kopia Q3, ale dany faktor = Q4
        curr = factors_q3.copy()
        curr[f] = factors_q4[f]

        rw_cf = compute_rw_from_factors(
            kg=curr[COL_KG],
            attachment=curr[COL_ATTACH],
            detachment=curr[COL_DETACH],
            w=curr[COL_W],
            p=curr[COL_P],
        )

        delta_rw = rw_cf - rw_q3
        effects[f"{f}_pure_effect"] = delta_rw * ead4

    return pd.Series(effects)


# ==========================
# GŁÓWNA LOGIKA
# ==========================

def main():
    # 1. Wczytanie danych
    df_q3_raw = read_input(INPUT_Q3_PATH)
    df_q4_raw = read_input(INPUT_Q4_PATH)

    # 2. Agregacja po CUSIP
    df_q3 = aggregate_by_cusip(df_q3_raw, "Q3")
    df_q4 = aggregate_by_cusip(df_q4_raw, "Q4")

    # 3. Połączenie Q3 i Q4 po CUSIP
    df = df_q3.merge(df_q4, on=COL_CUSIP, how="outer", indicator=True)

    # 4. Total RWA
    total_rwa_q3 = df[f"{COL_RWA}_Q3"].sum(skipna=True)
    total_rwa_q4 = df[f"{COL_RWA}_Q4"].sum(skipna=True)
    delta_rwa_total = total_rwa_q4 - total_rwa_q3

    # 5. Maski: nowe, znikniete, wspólne
    mask_new     = df["_merge"] == "right_only"   # tylko w Q4
    mask_gone    = df["_merge"] == "left_only"    # tylko w Q3
    mask_common  = df["_merge"] == "both"         # wspólne

    # 6. Efekt nowych papierów
    new_papers_effect = df.loc[mask_new, f"{COL_RWA}_Q4"].sum(skipna=True)

    # 7. Efekt zniknięcia papierów
    gone_papers_effect = - df.loc[mask_gone, f"{COL_RWA}_Q3"].sum(skipna=True)

    # 8. Wspólne CUSIPy
    common = df.loc[mask_common].copy()

    # RW z danych – używane do exposure effect
    common["RW_Q3_from_data"] = common[f"{COL_RWA}_Q3"] / common[f"{COL_EAD}_Q3"]
    common["RW_Q4_from_data"] = common[f"{COL_RWA}_Q4"] / common[f"{COL_EAD}_Q4"]
    common["RW_Q3_from_data"] = common["RW_Q3_from_data"].replace(
        [np.inf, -np.inf], 0
    ).fillna(0)
    common["RW_Q4_from_data"] = common["RW_Q4_from_data"].replace(
        [np.inf, -np.inf], 0
    ).fillna(0)

    # 8a. Efekt ekspozycji (na wspólnych)
    common["exposure_effect"] = common["RW_Q3_from_data"] * (
        common[f"{COL_EAD}_Q4"] - common[f"{COL_EAD}_Q3"]
    )
    exposure_effect_existing = common["exposure_effect"].sum(skipna=True)

    # 8b. Efekt faktorów – Shapley
    shapley_df = common.apply(factor_shapley_effects_row, axis=1)
    for col in shapley_df.columns:
        common[col] = shapley_df[col]

    shapley_sums = {
        col: common[col].sum(skipna=True) for col in shapley_df.columns
    }
    total_shapley_effect = sum(shapley_sums.values())

    # 8c. Efekt faktorów – PURE (counterfactual)
    pure_df = common.apply(factor_pure_effects_row, axis=1)
    for col in pure_df.columns:
        common[col] = pure_df[col]

    pure_sums = {
        col: common[col].sum(skipna=True) for col in pure_df.columns
    }
    total_pure_effect = sum(pure_sums.values())  # to NIE musi = total_shapley_effect

    # 9. Złożenie dekompozycji (używamy Shapley dla "oficjalnego" factor effect)
    total_explained = (
        new_papers_effect
        + gone_papers_effect
        + exposure_effect_existing
        + total_shapley_effect
    )

    unexplained = delta_rwa_total - total_explained

    # ==========================
    # OUTPUT – PODSUMOWANIE
    # ==========================

    print("===== RWA ATTRIBUTION (SSFA) =====")
    print(f"Total RWA Q3: {total_rwa_q3:,.2f}")
    print(f"Total RWA Q4: {total_rwa_q4:,.2f}")
    print(f"ΔRWA (Q4 - Q3): {delta_rwa_total:,.2f}")
    print()

    print("Kontrybucje (signed, oficjalnie używamy Shapley dla faktorów):")
    print(f"  + Nowe papiery (tylko Q4):         {new_papers_effect:,.2f}")
    print(f"  + Zniknięte papiery (sell/payoff): {gone_papers_effect:,.2f}")
    print(f"  + Zmiana EAD na wspólnych:         {exposure_effect_existing:,.2f}")
    print(f"  + Efekt faktorów ogółem (Shapley): {total_shapley_effect:,.2f}")
    print()
    print(f"Suma wyjaśniona (powinna ≈ ΔRWA):   {total_explained:,.2f}")
    print(f"Niewyjaśnione (rounding / model):   {unexplained:,.2f}")
    print()

    print("Rozbicie efektu faktorów – Shapley:")
    for f in FACTOR_LIST:
        key = f"{f}_shapley_effect"
        print(f"    {f:12s}: {shapley_sums.get(key, 0.0):,.2f}")

    print()
    print("Rozbicie efektu faktorów – PURE (co-if: tylko ten faktor się zmienia):")
    for f in FACTOR_LIST:
        key = f"{f}_pure_effect"
        print(f"    {f:12s}: {pure_sums.get(key, 0.0):,.2f}")


if __name__ == "__main__":
    main()
