import pandas as pd

# Sample DataFrames
df1 = pd.DataFrame({'Instrument_ID': [1, 2, 3, 4],
                    'Data_1': ['A', 'B', 'C', 'D']})

df2 = pd.DataFrame({'PARENT_CUSIP': ['Cusip1', 'Cusip2', 'Cusip3', 'Cusip4'],
                    'BIII': [10, 20, 30, 40]})

# Merge DataFrames based on PARENT_CUSIP
result_df = pd.merge(df1, df2, left_on='Instrument_ID', right_on='PARENT_CUSIP', how='left')

# Drop the redundant column
result_df.drop('PARENT_CUSIP', axis=1, inplace=True)

print(result_df)


import pandas as pd

def extract_nonzero_rows(workbook_path, sheet_name, columns_list):
    """
    Extract rows from a specified sheet in a workbook where values in specified columns are different than 0.

    Parameters:
    - workbook_path (str): Path to the Excel workbook.
    - sheet_name (str): Name of the sheet in the workbook.
    - columns_list (list): List of column names to check for non-zero values.

    Returns:
    - pd.DataFrame: DataFrame containing rows where values in specified columns are non-zero.
    """

    # Read the specified sheet from the workbook
    df = pd.read_excel(workbook_path, sheet_name)

    # Filter rows where values in specified columns are different than 0
    non_zero_rows = df[(df[columns_list] != 0).any(axis=1)]

    return non_zero_rows

# Example usage:
workbook_path = 'path/to/your/workbook.xlsx'
sheet_name = 'Sheet1'
columns_to_check = ['Column1', 'Column2', 'Column3']

result_df = extract_nonzero_rows(workbook_path, sheet_name, columns_to_check)
print(result_df)


import pandas as pd

def check_relationship_and_save_missing(DF1, DF2):
    """
    Check if all elements from the "Security" column of DF1 exist in the "Instrument_ID" column of DF2,
    and vice versa. Save the missing values to an Excel file named "MissingIP.xlsx".

    Parameters:
    - DF1: First DataFrame
    - DF2: Second DataFrame

    Returns:
    - True if all elements from DF1["Security"] are in DF2["Instrument_ID"] and vice versa, False otherwise.
    """

    # Extract unique values from "Security" column of DF1
    security_values_df1 = set(DF1["Security"])

    # Extract unique values from "Instrument_ID" column of DF2
    instrument_id_values_df2 = set(DF2["Instrument_ID"])

    # Check if all elements from DF1["Security"] are in DF2["Instrument_ID"]
    relationship_df1_to_df2 = security_values_df1.issubset(instrument_id_values_df2)

    # Check if all elements from DF2["Instrument_ID"] are in DF1["Security"]
    relationship_df2_to_df1 = instrument_id_values_df2.issubset(security_values_df1)

    # Create DataFrames with missing values
    missing_df1_to_df2 = pd.DataFrame(list(security_values_df1 - instrument_id_values_df2), columns=["Missing_Security_in_DF2"])
    missing_df2_to_df1 = pd.DataFrame(list(instrument_id_values_df2 - security_values_df1), columns=["Missing_Instrument_ID_in_DF1"])

    # Save missing values to Excel
     with pd.ExcelWriter(excel_file_path, engine='xlsxwriter') as writer:
    missing_df1_to_df2.to_excel("MissingIP.xlsx", sheet_name="Missing_Security_in_DF2", index=False)
    missing_df2_to_df1.to_excel("MissingIP.xlsx", sheet_name="Missing_Instrument_ID_in_DF1", index=False, mode='a')

    # Return the overall relationship result
    return relationship_df1_to_df2 and relationship_df2_to_df1

# Example usage:
# Assuming DF1 and DF2 are your DataFrames
# Replace 'your_dataframe1.csv' and 'your_dataframe2.csv' with the actual file or data sources you have
DF1 = pd.read_csv('your_dataframe1.csv')
DF2 = pd.read_csv('your_dataframe2.csv')

# Check the relationship and save missing values
relationship_result = check_relationship_and_save_missing(DF1, DF2)

# Print the overall relationship result
print("All elements from DF1[\"Security\"] exist in DF2[\"Instrument_ID\"] and vice versa:", relationship_result)
